\documentclass[english]{lni}

%\IfFileExists{latin1.sty}{\usepackage{latin1}}{\usepackage{isolatin1}}

\usepackage{graphicx}
\usepackage{url}
\usepackage{listings}
\lstset{aboveskip=0.8ex,
        belowskip=0.8ex,
        xleftmargin=2ex,
        showstringspaces=false, % no special string space
        mathescape=true,
        flexiblecolumns=false,
        basewidth=0.52em,
        basicstyle=\small\ttfamily}
\lstset{literate={->}{{$\rightarrow{}\!\!\!$}}3
       }
\lstnewenvironment{curry}{}{}
\newcommand{\listline}{\vrule width0pt depth1.75ex}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\ccode}[1]{``\code{#1}''}
\newcommand{\bs}{\char92} % backslash
\newcommand{\us}{\char95} % underscore

\author{
Michael Hanus
\quad
Bj{\"o}rn Peem{\"o}ller
\quad
Fabian Reck \\
\\
Institut f\"ur Informatik, CAU Kiel, D-24098 Kiel, Germany \\
\texttt{\{mh|bjp|fre\}@informatik.uni-kiel.de}
}
\title{Search Strategies for Functional Logic Programming}
\begin{document}
\maketitle

\begin{abstract}
In this paper we discuss our practical experiences
with the use of different search strategies
in functional logic programs.
In particular, we show that complete strategies,
like breadth-first search or iterative deepening search,
are a reasonable alternative to incomplete strategies, like depth-first
search, that have been favored in the past for logic programming.
\end{abstract}

\section{Introduction}

Functional logic languages combine the most important
features of functional and logic programming in a single language
(see \cite{AntoyHanus10CACM,Hanus07ICLP} for recent surveys).
In particular, they provide higher-order functions and demand-driven
evaluation from functional programming together with logic programming features
like non-deterministic search and computing with partial information
(logic variables).
This combination
led to new design patterns \cite{AntoyHanus02FLOPS,AntoyHanus11WFLP}
and better abstractions for application programming,
e.g., as shown for programming with databases
\cite{BrasselHanusMueller08PADL,Fischer05},
GUI programming \cite{Hanus00PADL},
web programming \cite{Hanus01PADL,Hanus06PPDP,HanusKoschnicke10PADL},
or string parsing \cite{CaballeroLopez99}.
Moreover, it is also a good basis
to teach the ideas of functional and logic programming,
or declarative programming in general,
with a single computation model and programming language
\cite{Hanus97DPLE}.

An important feature of logic programming languages
is non-deterministic search.
In Prolog, which is still the standard language for logic programming,
non-deterministic search is implemented via backtracking,
which corresponds to a depth-first search traversal
through the SLD proof tree \cite{Lloyd87}.
Due to this feature of Prolog,
logic programming is often considered as unification and backtracking
as shown by approaches to add logic programming features
to existing functional languages
(e.g., \cite{ClaessenLjungloef00,Hinze01}).
This limited ``backtracking'' view of logic programming
is also harmful to beginners when newbies
define their family relationships using a Prolog rule like
\begin{lstlisting}
sibling(X,Y) :- sibling(Y,X).
\end{lstlisting}
In such cases, one has to explain from the beginning
the pitfalls of backtracking.
From a declarative point of view,
a logic program defines a set of rules
and a logic programming system tries to find
a solution to a query w.r.t.\ the set of rules.
In order to abstract from operational details,
the search strategy has to be complete.
Due to these considerations,
the functional logic language Curry \cite{Hanus06Curry}
does not fix a particular search strategy
so that different Curry implementations can support
different (or also several) search strategies.
Moreover, Curry implementations also
support encapsulated search
where non-deterministic computations are represented
in a data structure so that different search strategies
can be implemented as tree traversals
\cite{BrasselHanusHuch04JFLP,HanusSteiner98PLILP,Lux99FLOPS}.

In this paper, we present our practical results
with different search strategies implemented
in a new implementation of Curry, called
KiCS2 \cite{BrasselHanusPeemoellerReck11}.
KiCS2 compiles Curry programs into Haskell programs
where non-deterministic computations are implemented
as tree structures so that flexible search strategies
are supported.
Although the incomplete depth-first search strategy
is the most efficient one (provided that it is able
to find a result value),
we show that complete strategies,
like breadth-first search or iterative deepening search,
are a reasonable alternative that does not force
the programmer to consider the applied search strategy
in his program.

In the next section, we briefly recall some principles
of functional logic programming and the programming language Curry
that are necessary to understand the remaining part of the paper.
Different search strategies and their implementation
are discussed in Section~\ref{sec:strategies}.
These strategies are evaluated with a number of benchmarks
in Section~\ref{sec:benchmarks}
before we conclude in Section~\ref{sec:conclusions}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Functional Logic Programming and Curry}

Integrated functional logic programming languages
combine features 
from functional programming (demand-driven evaluation, parametric
polymorphism, higher-order functions) and logic programming
(computing with partial information, unification, constraints).
Recent surveys are available in \cite{AntoyHanus10CACM,Hanus07ICLP}.
Curry \cite{Hanus06Curry} is a functional logic language
which extends lazy functional programming as to be found in
Haskell \cite{PeytonJones03Haskell} and supports these features.
Another functional logic language based on similar principles is
${\cal TOY}$ \cite{Lopez-FraguasSanchez-Hernandez99}.
However, ${\cal TOY}$ does not offer flexible search strategies
by a concept of encapsulating search
(although it provides a concept of nested computation spaces
in order to deal with failures in functional logic
programming \cite{LopezSanchez04,SanchezHernandez06}).
Therefore, we use Curry throughout this paper, although
the concepts presented here could be also integrated in
other functional logic languages.

A Curry program consists of the definition of data types and
operations on these types. 
Since the syntax of Curry is close to Haskell,
variables and function names usually
start with lowercase letters and the names of type and data constructors
start with an uppercase letter. The application of $f$
to $e$ is denoted by juxtaposition (``$f~e$'').
In addition, Curry allows free (logic) 
variables in conditions and right-hand sides of defining rules.
Note that in a functional logic language
operations might yield more than one result on the same input due to 
the logic programming features.
For instance, Curry contains a \emph{choice} operation defined by:
%
\begin{curry}
x ? _ = x
_ ? y = y
\end{curry}
%
The choice operation can be used to define other non-deterministic operations
like
%
\begin{curry}
coin = 0 ? 1  
\end{curry}
Thus, the expression \ccode{coin} has two values: \code{0} and \code{1}.
If expressions have more than one value, one wants to select
intended values according to some constraints,
typically in conditions of program rules.
A \emph{rule} has the form
\begin{curry}
$f~t_1\ldots{}t_n$ | $c$ = $e$
\end{curry}
where the (optional) condition $c$ is a \emph{constraint},
i.e., an expression of the built-in type
\code{Success}. For instance, the trivial constraint
\code{success} is a value of type \code{Success} that
denotes the always satisfiable constraint.
Thus, we say that a constraint $c$ is \emph{satisfied} if it
can be evaluated to \code{success}.
An \emph{equational constraint} $e_1 \,\code{=:=}\, e_2$ is satisfiable
if both sides $e_1$ and $e_2$ are reducible to unifiable values.
%Furthermore, if $c_1$ and $c_2$ are constraints,
%\code{$c_1\,$\&$\,\,c_2$} denotes their concurrent conjunction
%(i.e., both argument constraints are concurrently evaluated).

As a simple example, consider the following Curry program
which defines a polymorphic 
data type for lists and operations to compute the 
concatenation of lists and the last element of a list:\footnote{Note
that lists are a built-in data type with a more convenient syntax, 
e.g., one can write \code{[x,y,z]} instead of \code{x:y:z:[]}
and \code{[a]} instead of the list type \ccode{List a}.}
%
\begin{curry}
data List a = [] | a : List a    --[a] denotes "List a"

-- "++" is a right-associative infix operator
(++) :: [a] -> [a] -> [a]
[]     ++ ys = ys
(x:xs) ++ ys = x : (xs ++ ys)

last :: [a] -> a
last xs | (ys ++ [z]) =:= xs
        = z                    where ys,z free
\end{curry}
%
Logic programming is supported by admitting function calls with free
variables (e.g., \code{(ys++[z])} in the rule defining \code{last})
and constraints in the condition of a defining rule. In contrast to
Prolog, free variables need to be declared explicitly to make their
scopes clear (e.g., \ccode{where ys,z free} in the example).
A conditional rule is applicable if its condition  is satisfiable.
Thus, the rule defining \code{last} states in its condition
that \code{z} is the last element of a given list
\code{xs} if there exists a list \code{ys}
such that the concatenation of \code{ys} and the one-element list
\code{[z]} is equal to the given list \code{xs}.

Curry also offers standard features of
functional languages, like modules or monadic I/O
which is identical to Haskell's I/O concept \cite{Wadler97}.
Thus, \ccode{IO $\alpha$} denotes the type of an I/O action that returns values
of type $\alpha$.

The operational semantics of Curry is based on an optimal evaluation strategy
\cite{AntoyEchahedHanus00JACM} which is a conservative extension
of lazy functional programming and (concurrent) logic programming.
A big-step and a small-step operational semantics of Curry
can be found in \cite{AlbertHanusHuchOliverVidal05}.
Curry's semantics is sound in the sense of logic programming,
i.e., each computed result is correct and for each
correct result there is a more general computed one
\cite{AntoyEchahedHanus00JACM}.
In order to achieve completeness,
one has to take all possible non-deterministic derivation paths
into account. In contrast to Prolog, which fixes
a (potentially incomplete) depth-first search strategy to find solutions,
Curry does not fix a particular search strategy.
Thus, different Curry implementations
can support various search strategies.
For instance, the Curry implementation PAKCS \cite{Hanus10PAKCS},
which compiles Curry programs into Prolog programs,
supports only a depth-first search strategy.
MCC \cite{Lux99FLOPS} compiles Curry programs into C programs
and uses also a depth-first search strategy to find all
solutions of a given top-level goal.
In addition, MCC offers the encapsulation of search
(see below) so that other search strategies,
like a complete breadth-first search strategy, can be used
inside a Curry program.
The Curry implementation KiCS \cite{BrasselHuch07,BrasselHuch09},
which compiles Curry programs into Haskell programs,
offers depth-first and breadth-first search strategies
for top-level goals as well the encapsulation of search
with user-definable strategies.
In this paper we consider the Curry implementation
KiCS2 \cite{BrasselHanusPeemoellerReck11},
which is based on similar ideas than KiCS but uses
a different compilation model avoiding side effects
to enable better optimizations for target programs.
KiCS2 also offers different search strategies for top-level goals
and the encapsulation of search with user-definable strategies,
which is described next.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Search Strategies}
\label{sec:strategies}

As mentioned above, Curry does not enforce a particular search
strategy. A Curry implementation
can provide different search strategies to find solutions
or values for a given constraint or expression.
The most advanced system in this respect is
KiCS2 \cite{BrasselHanusPeemoellerReck11},
which supports the evaluation of top-level expressions
with depth-first search, breadth-first search,
iterative deepening search, or parallel search strategies.
Curry supports flexibility since all operations with side effects
are collected in monadic I/O operations \cite{Wadler97}.
As a consequence of this computation model,
all non-deterministic computations between I/O operations
must be encapsulated since one can not apply two alternative
I/O operations to an existing ``world''
and non-deterministically proceed with two alternative worlds
(``one can not duplicate the world'').
Therefore, Curry offers the encapsulation of search
by representing non-deterministic computations
in a data structure so that the computation of different solutions
(one solution or all solutions) can conceptually be implemented
as traversals on this data structure.

An early approach to encapsulating search
\cite{HanusSteiner98PLILP,Lux99FLOPS}
is based on a primitive search operator
\begin{curry}
try :: (a->Success) -> [a->Success]
\end{curry}
that takes a constraint abstraction, e.g., \code{(\bs{}x->x\,=:=\,coin)},
as input, evaluates it until the first non-deterministic step occurs,
and returns the result: the empty list in case of failure, a list with a single
element in case of success, or a list with at least two elements representing
a nondeterministic choice. For instance,
\code{try\,(\bs{}x->x\,=:=\,coin)} evaluates to
\code{[\bs{}x->x\,=:=\,0,\,\bs{}x->x\,=:=\,1]}.
Based on this primitive, one can define various search strategies
to explore the search space and return its solutions.
\cite{Lux99FLOPS} shows an implementation of this primitive.

Although typical search operators of Prolog,
like \code{findall}, \code{once}, or negation-as-failure,
can be implemented using the primitive \code{try},
it became also clear that the combination with demand-driven evaluation
and sharing causes further complications.
For instance, in an expression like
\begin{curry}
let y=coin in try (\x->x=:=y)
\end{curry}
it is not obvious whether the evaluation of \code{coin} (introduced outside
but demanded inside the search operator) should be encapsulated or not.
Hence, the result of this expression might depend on the evaluation order.
For instance,
if \code{coin} is evaluated before the \code{try} expression,
it results in two computations where \code{y} is bound to \code{0}
in one computation and to \code{1} in the other computation.
Hence, \code{try} does not encapsulate the nondeterminism of \code{coin}
(this is the semantics of \code{try} implemented in \cite{Lux99FLOPS}).
However, if \code{coin} is evaluated inside the capsule of \code{try}
(because it is not demanded before), then the nondeterminism of
\code{coin} is encapsulated.
These and more peculiarities are discussed in \cite{BrasselHanusHuch04JFLP}.
Furthermore, the order of the solutions might depend on the
textual order of program rules or the evaluation time
(e.g., in parallel implementations).
Therefore, \cite{BrasselHanusHuch04JFLP} contains a proposal
for another primitive search operator:
\begin{curry}
getSearchTree :: a -> IO (SearchTree a)
\end{curry}
Since \code{getSearchTree} is an I/O action, its result (in particular,
the order of solutions) depends on the current environment, e.g.,
time of evaluation.
It takes an expression and delivers a search tree representing
the search space when evaluating the input:
\begin{curry}
data SearchTree a = Value a | Fail | Or (SearchTree a) (SearchTree a)
\end{curry}
\code{(Value v)} and \code{Fail} represents a single value
or a failure (i.e., no value), respectively,
and \code{(Or t1 t2)} represents a choice (i.e., a non-deterministic value)
between two search trees \code{t1} and \code{t2}.
To avoid the complications w.r.t.\ shared variables,
\code{getSearchTree} implements a \emph{strong encapsulation view},
i.e., conceptually, the argument of \code{getSearchTree}
is cloned before the evaluation starts in order to cut any sharing
with the environment.
Furthermore, the structure of the search tree is computed lazily
so that an expression with infinitely many values does not cause
the nontermination of the search operator if one is interested in only
one solution.

This primitive has been implemented for the first time
in KiCS \cite{BrasselHuch07,BrasselHuch09}
and it is also provided in KiCS2 \cite{BrasselHanusPeemoellerReck11}
considered in this paper.
With this primitive,
the programmer can define its own search strategy as
\code{SearchTree} traversals in order to
collect all non-deterministic values into a list structure.
For instance, a depth-first search strategy can be easily defined
as follows:
\begin{curry}
allValuesDFS :: SearchTree a -> [a]
allValuesDFS Fail      = []
allValuesDFS (Value x) = [x]
allValuesDFS (Or x y)  = allValuesDFS x ++ allValuesDFS y
\end{curry}
Note that the lazy evaluation of traversal operations like
\code{allValuesDFS} has the advantage that the search strategy
is decoupled from the control. For instance, a single value
of a non-deterministic expression $exp$ can be printed by
\begin{curry}
getSearchTree $exp$ >>= print . head . allValuesBFS
\end{curry}
even if $exp$ has infinitely many values.
This is in contrast to Prolog's constructs for controlling
search where different operators are necessary to compute
one or all solutions.

As a further example, we show an implementation
of a breadth-first search strategy:
\begin{curry}
allValuesBFS :: SearchTree a -> [a]
allValuesBFS t = collect [t]

collect []     = []
collect (t:ts) = values (t:ts) ++ collect (children (t:ts))

values []           = []
values (Fail:ts)    = values ts
values (Value x:ts) = x : values ts
values (Or _ _:ts)  = values ts

children []           = []
children (Fail:ts)    = children ts
children (Value _:ts) = children ts
children (Or x y:ts)  = x:y:children ts
\end{curry}
The operation \code{values} extracts the values
in each level of the tree and the operation \code{children}
extracts all direct ancestors of a level in order to recursively
collect their values.

It is well known that depth-first search lacks completeness,
i.e., it is not able to compute all existing values.
For instance, consider the following operation
that non-deterministically returns all increasing numbers from a given value:
\begin{curry}
f n = f (n+1) ? n
\end{curry}
Obviously, \code{0} is a value of \code{(f 0)}, which can be printed
by the expression
\begin{curry}
getSearchTree (f 0) >>= print . head . allValuesBFS
\end{curry}
However, if we replace \code{allValuesBFS} by \code{allValuesDFS},
we run into an infinite loop since \ccode{?} returns
its values in the given left-to-right order.
In order to abstract from the details of the evaluation order,
it would be preferable to use complete search strategies.
Complete strategies are often neglected due to performance reasons.
Thus, we evaluate and compare in the next section the
performance behavior of different search strategies in KiCS2.

In principle, the operator to encapsulate search can be
also used to implement an interactive top-level
to print all values of an expression as requested by the user.
For instance, the following operation prints all elements
of a given list as requested by the user:
\begin{curry}
printResults :: [_] -> IO ()
printResults [] = putStrLn "No more values"
printResults (x:xs) =
  do print x
     putStr "More values? "
     inp <- getLine
     if inp=="yes" then printResults xs
                   else done
\end{curry}
Hence, a Prolog-like top-level interactive environment
to show all values of an expression $exp$ in depth-first order
can be obtained by
\begin{curry}
getSearchTree $exp$ >>= printResults . allValuesDFS
\end{curry}
In addition, we can print the results in breadth-first order
by using \code{allValuesBFS} instead of \code{allValuesDFS}.
Based these ideas, KiCS2 provides an interactive top-level
where the user can select various search strategies
(depth-first, breadth-first, iterative deepening, parallel).
However, the top-level search in KiCS2 is not implemented
via the primitive encapsulation operator but in more direct
monadic style (see also \cite{BrasselHanusPeemoellerReck11})
in order to avoid the explicit construction
of the \code{SearchTree} structure.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Benchmarks}
\label{sec:benchmarks}

Compare DFS, BFS, IDS (top-level and encapsulated, all solutions and first sol)

Hopefully, they show what we want...

\section{Conclusions}
\label{sec:conclusions}

Complete strategies could be the default!

If efficiency important and DFS safe (e.g., finite search space): use DFS

Future work: approximate safeness of DFS


%\bibliography{mh}
\bibliography{paper}

\end{document}
